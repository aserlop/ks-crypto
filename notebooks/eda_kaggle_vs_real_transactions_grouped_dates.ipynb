{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA KAGGLE VS REAL TRANSACTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/default/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, plot\n",
    "import seaborn as sns\n",
    "from ks_crypto.lib.spark_conn import create_yarn_connection\n",
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "findspark.init()\n",
    "spark = create_yarn_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DANON_FULL_TABLENAME = \"kschool-crypto:ks_crypto_dataset.danon_transactions\"\n",
    "TRANSACTIONS_FULL_TABLENAME = \"bigquery-public-data:crypto_bitcoin.transactions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202804"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danon_df = \\\n",
    "    spark.read.format('bigquery') \\\n",
    "    .option('table', DANON_FULL_TABLENAME) \\\n",
    "    .load() \\\n",
    "    .select('transaction_hash')\\\n",
    "    .persist()\n",
    "\n",
    "danon_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = \\\n",
    "    spark.read.format('bigquery') \\\n",
    "    .option('table', TRANSACTIONS_FULL_TABLENAME) \\\n",
    "    .load()\\\n",
    "    .select(F.col('hash').alias('transaction_hash'),\n",
    "            'lock_time',\n",
    "            'block_hash',\n",
    "            'block_timestamp',\n",
    "            'block_timestamp_month',\n",
    "            'input_count',\n",
    "            'output_count',\n",
    "            'input_value',\n",
    "            'output_value',\n",
    "            'is_coinbase',\n",
    "            'fee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JOIN REAL TRANSACTIONS WITH KAGGLE ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df = \\\n",
    "    transactions_df\\\n",
    "    .join(danon_df,\n",
    "          on=['transaction_hash'],\n",
    "          how='inner')\\\n",
    "    .persist()\n",
    "\n",
    "sampled_transactions_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OBTAIN MIN-MAX DATES OF TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df.select(F.min('block_timestamp_month'), F.max('block_timestamp_month')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.filter(F.col('block_timestamp_month').between('2016-01-01', '2017-10-01')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df.filter(F.col('block_timestamp_month').between('2016-01-01', '2017-10-01')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CHECK HOW MANY DIF DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_transactions_df = \\\n",
    "    transactions_df.filter(F.col('block_timestamp_month').between('2016-01-01', '2017-10-01'))\\\n",
    "    .persist()\n",
    "\n",
    "period_transactions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df\\\n",
    "    .drop_duplicates(['block_timestamp'])\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = \\\n",
    "    sampled_transactions_df\\\n",
    "    .groupBy('block_timestamp')\\\n",
    "    .count()\\\n",
    "    .orderBy('block_timestamp')\\\n",
    "    .toPandas()\n",
    "\n",
    "px.line(ts, x='block_timestamp', y='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df\\\n",
    "    .filter((F.col('block_timestamp_month')== '2016-01-01') & (F.col('block_timestamp') == '2016-01-13 23:40:57'))\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CHECK DIFF HOURS IN THE FIRST AND LAST EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_transactions_df\\\n",
    "    .select('block_timestamp')\\\n",
    "    .withColumn('lag_block_timestamp', F.lag('block_timestamp').over(w))\\\n",
    "    .withColumn('diff_hours', (F.col('block_timestamp').cast('long') -  F.col('lag_block_timestamp').cast('long')) / 3600)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_ord = Window.orderBy('block_timestamp')\n",
    "w_id = Window.partitionBy('block_timestamp')\n",
    "\n",
    "diff_hours_lag_fun = (F.col('block_timestamp').cast('long') -  F.col('lag_block_timestamp').cast('long')) / 3600\n",
    "is_more_hours_lag_cond = (diff_hours_lag_fun > 3) | (F.col('lag_block_timestamp').isNull())\n",
    "\n",
    "diff_hours_lead_fun = (F.col('lead_block_timestamp').cast('long') -  F.col('block_timestamp').cast('long')) / 3600\n",
    "is_more_hours_lead_cond = (diff_hours_lead_fun > 3) | (F.col('lead_block_timestamp').isNull())\n",
    "\n",
    "\n",
    "first_last_transactions_df = \\\n",
    "sampled_transactions_df\\\n",
    "    .select('block_timestamp')\\\n",
    "    .withColumn('lag_block_timestamp', F.lag('block_timestamp').over(w_ord))\\\n",
    "    .withColumn('is_first_in_period', F.when(is_more_hours_lag_cond, 1).otherwise(0))\\\n",
    "    .withColumn('is_first_in_period', F.max('is_first_in_period').over(w_id))\\\n",
    "    .withColumn('lead_block_timestamp', F.lead('block_timestamp').over(w_ord))\\\n",
    "    .withColumn('is_last_in_period', F.when(is_more_hours_lead_cond, 1).otherwise(0))\\\n",
    "    .withColumn('is_last_in_period', F.max('is_last_in_period').over(w_id))\\\n",
    "    .drop(*['lead_block_timestamp', 'lag_block_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last_transactions_df\\\n",
    "    .filter((F.col('is_last_in_period') == 1) | (F.col('is_first_in_period') == 1))\\\n",
    "    .dropDuplicates()\\\n",
    "    .withColumn('lead_block_timestamp', F.lead('block_timestamp').over(w_ord))\\\n",
    "    .withColumn('range_hours', diff_hours_lead_fun)\\\n",
    "    .filter((F.col('is_first_in_period') == 1))\\\n",
    "    .groupBy('range_hours').count().orderBy(F.desc('range_hours'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last_transactions_df\\\n",
    "    .groupBy('block_timestamp')\\\n",
    "    .agg(F.count(F.lit(1)).alias('count'), \n",
    "         F.sum('is_first_in_period').alias('sum_is_first_in_period'),\n",
    "         F.sum('is_last_in_period').alias('sum_is_last_in_period'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PLOT GROUPED VARS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block_timestamp        16047\n",
       "count                  16047\n",
       "mean_input_count       16047\n",
       "mean_output_count      16047\n",
       "mean_input_value       16047\n",
       "mean_output_value      16047\n",
       "sum_input_count        16047\n",
       "sum_output_count       16047\n",
       "sum_input_value        16047\n",
       "sum_output_value       16047\n",
       "median_input_count     16047\n",
       "median_output_count    16047\n",
       "median_input_value     16047\n",
       "median_output_value    16047\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['input_count', 'output_count', 'input_value', 'output_value']\n",
    "mean_fun_list = [F.mean(c).alias('mean_'+ c) for c in num_cols]\n",
    "sum_fun_list = [F.sum(c).alias('sum_'+ c) for c in num_cols]\n",
    "median_fun_list = [F.expr(f'percentile_approx({c}, 0.5)').alias('median_'+c) for c in num_cols]\n",
    "\n",
    "full_ts = \\\n",
    "    period_transactions_df\\\n",
    "    .groupBy(F.date_trunc('hour', 'block_timestamp').alias('block_timestamp'))\\\n",
    "    .agg(F.count(F.lit(1)).alias('count'),\n",
    "         *mean_fun_list,\n",
    "         *sum_fun_list,\n",
    "         *median_fun_list)\\\n",
    "    .orderBy('block_timestamp')\\\n",
    "    .toPandas()\n",
    "\n",
    "full_ts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block_timestamp        121\n",
       "count                  121\n",
       "mean_input_count       121\n",
       "mean_output_count      121\n",
       "mean_input_value       121\n",
       "mean_output_value      121\n",
       "sum_input_count        121\n",
       "sum_output_count       121\n",
       "sum_input_value        121\n",
       "sum_output_value       121\n",
       "median_input_count     121\n",
       "median_output_count    121\n",
       "median_input_value     121\n",
       "median_output_value    121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['input_count', 'output_count', 'input_value', 'output_value']\n",
    "mean_fun_list = [F.mean(c).alias('mean_'+ c) for c in num_cols]\n",
    "sum_fun_list = [F.sum(c).alias('sum_'+ c) for c in num_cols]\n",
    "median_fun_list = [F.expr(f'percentile_approx({c}, 0.5)').alias('median_'+c) for c in num_cols]\n",
    "\n",
    "ts = \\\n",
    "sampled_transactions_df\\\n",
    "    .groupBy(F.date_trunc('hour', 'block_timestamp').alias('block_timestamp'))\\\n",
    "    .agg(F.count(F.lit(1)).alias('count'),\n",
    "         *mean_fun_list,\n",
    "         *sum_fun_list,\n",
    "         *median_fun_list)\\\n",
    "    .orderBy('block_timestamp')\\\n",
    "    .toPandas()\n",
    "ts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_list = ['count', 'mean_input_count', 'mean_output_count',\n",
    "       'mean_input_value', 'mean_output_value', 'sum_input_count',\n",
    "       'sum_output_count', 'sum_input_value', 'sum_output_value',\n",
    "       'median_input_count', 'median_output_count', 'median_input_value',\n",
    "       'median_output_value']\n",
    "\n",
    "for var in v_list:\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=full_ts['block_timestamp'], y=full_ts[var],\n",
    "                             mode='lines',\n",
    "                             name='full_ts'))\n",
    "    fig.add_trace(go.Scatter(x=ts['block_timestamp'], y=full_ts[var],\n",
    "                             mode='lines+markers',\n",
    "                             name='ts'))\n",
    "\n",
    "    plot(fig, filename = f'{var}.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_ks_crypto",
   "language": "python",
   "name": "p_ks_crypto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
