{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA ADDRESS NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/default/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, plot\n",
    "import seaborn as sns\n",
    "from ks_crypto.lib.spark_conn import create_yarn_connection\n",
    "from ks_crypto.lib import constants as C\n",
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "findspark.init()\n",
    "spark = create_yarn_connection()\n",
    "\n",
    "import graphframes as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.broadcastTimeout\",  \"1000000\")\n",
    "spark.sparkContext.setCheckpointDir('/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DANON_FULL_TABLENAME = \"kschool-crypto:ks_crypto_dataset.danon_transactions\"\n",
    "TRANSACTIONS_FLATTEN_FULL_TABLENAME = \"kschool-crypto.ks_crypto_dataset.transactions_flatten\"\n",
    "F_MIN = '2016-01-01'\n",
    "F_MAX = '2017-10-01'\n",
    "\n",
    "PERIOD_DIC = {\n",
    "    1: ['2016-01-01 02:50:56', '2016-01-01 08:50:56'],\n",
    "    2: ['2016-01-13 23:40:57', '2016-01-14 05:40:57'],\n",
    "    3: ['2016-01-27 04:01:32', '2016-01-27 10:01:32'],\n",
    "    4: ['2016-02-07 17:04:34', '2016-02-07 23:04:34'],\n",
    "    5: ['2016-02-20 05:43:02', '2016-02-20 11:43:02'],\n",
    "    6: ['2016-03-05 14:13:59', '2016-03-05 20:13:59'],\n",
    "    7: ['2016-03-19 03:05:12', '2016-03-19 09:05:12'],\n",
    "    8: ['2016-04-01 21:14:12', '2016-04-02 03:14:12'],\n",
    "    9: ['2016-04-14 22:53:05', '2016-04-15 04:53:05'],\n",
    "    10: ['2016-04-29 01:55:24', '2016-04-29 07:55:24'],\n",
    "    11: ['2016-05-11 23:10:38', '2016-05-12 05:10:38'],\n",
    "    12: ['2016-05-25 15:34:08', '2016-05-25 21:34:08'],\n",
    "    13: ['2016-06-08 18:08:38', '2016-06-09 00:08:38'],\n",
    "    14: ['2016-06-21 22:20:59', '2016-06-22 04:20:59'],\n",
    "    15: ['2016-07-05 17:19:48', '2016-07-05 23:19:48'],\n",
    "    16: ['2016-07-19 17:27:38', '2016-07-19 23:27:38'],\n",
    "    17: ['2016-08-03 10:01:52', '2016-08-03 16:01:52'],\n",
    "    18: ['2016-08-16 13:52:56', '2016-08-16 19:52:56'],\n",
    "    19: ['2016-08-30 06:26:15', '2016-08-30 12:26:15'],\n",
    "    20: ['2016-09-12 19:15:16', '2016-09-13 01:15:16'],\n",
    "    21: ['2016-09-25 21:50:08', '2016-09-26 03:50:08'],\n",
    "    22: ['2016-10-09 00:36:09', '2016-10-09 06:36:09'],\n",
    "    23: ['2016-10-23 10:58:25', '2016-10-23 16:58:25'],\n",
    "    24: ['2016-11-06 07:34:13', '2016-11-06 13:34:13'],\n",
    "    25: ['2016-11-18 23:59:04', '2016-11-19 05:59:04'],\n",
    "    26: ['2016-12-02 19:42:18', '2016-12-03 01:42:18'],\n",
    "    27: ['2016-12-15 20:26:20', '2016-12-16 02:26:20'],\n",
    "    28: ['2016-12-29 09:37:43', '2016-12-29 15:37:43'],\n",
    "    29: ['2017-01-11 12:49:44', '2017-01-11 18:49:44'],\n",
    "    30: ['2017-01-23 15:14:17', '2017-01-23 21:14:17'],\n",
    "    31: ['2017-02-05 13:26:08', '2017-02-05 19:26:08'],\n",
    "    32: ['2017-02-19 01:06:55', '2017-02-19 07:06:55'],\n",
    "    33: ['2017-03-04 11:05:28', '2017-03-04 17:05:28'],\n",
    "    34: ['2017-03-18 00:21:41', '2017-03-18 06:21:41'],\n",
    "    35: ['2017-03-31 07:38:56', '2017-03-31 13:38:56'],\n",
    "    36: ['2017-04-13 20:45:41', '2017-04-14 02:45:41'],\n",
    "    37: ['2017-04-27 20:05:46', '2017-04-28 02:05:46'],\n",
    "    38: ['2017-05-10 20:00:50', '2017-05-11 02:00:50'],\n",
    "    39: ['2017-05-23 22:00:57', '2017-05-24 04:00:57'],\n",
    "    40: ['2017-06-05 05:37:21', '2017-06-05 11:37:21'],\n",
    "    41: ['2017-06-18 16:13:50', '2017-06-18 22:13:50'],\n",
    "    42: ['2017-07-02 13:09:19', '2017-07-02 19:09:19'],\n",
    "    43: ['2017-07-15 03:48:27', '2017-07-15 09:48:27'],\n",
    "    44: ['2017-07-28 01:01:49', '2017-07-28 07:01:49'],\n",
    "    45: ['2017-08-10 05:38:54', '2017-08-10 11:38:54'],\n",
    "    46: ['2017-08-25 00:54:59', '2017-08-25 06:54:59'],\n",
    "    47: ['2017-09-07 03:20:23', '2017-09-07 09:20:23'],\n",
    "    48: ['2017-09-19 00:54:47', '2017-09-19 06:54:47']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_period_block_timestamp_dic(input_df, old_num_hours, new_num_hours):\n",
    "\n",
    "    w_ord = Window.orderBy(C.BLOCK_TIMESTAMP)\n",
    "    w_id = Window.partitionBy(C.BLOCK_TIMESTAMP)\n",
    "\n",
    "    diff_hours_lag_fun = (\n",
    "        (F.col(C.BLOCK_TIMESTAMP).cast('long') -\n",
    "         F.col(f'lag_{C.BLOCK_TIMESTAMP}').cast('long')) / 3600).cast('int')\n",
    "    is_more_hours_lag_cond = \\\n",
    "        (diff_hours_lag_fun > old_num_hours) | (F.col(f'lag_{C.BLOCK_TIMESTAMP}').isNull())\n",
    "\n",
    "    final_cols_dic = {\n",
    "        'period': F.row_number().over(w_ord),\n",
    "        'f_min_period': F.col(C.BLOCK_TIMESTAMP).cast('string'),\n",
    "        'f_max_period': (F.col(C.BLOCK_TIMESTAMP) + F.expr(f'INTERVAL {new_num_hours} HOURS')).cast('string')\n",
    "    }\n",
    "\n",
    "    final_cols_list = [v.alias(k) for k, v in final_cols_dic.items()]\n",
    "\n",
    "    period_df = \\\n",
    "        input_df \\\n",
    "        .filter(F.col('is_deanonymized') == 1)\\\n",
    "        .withColumn(f'lag_{C.BLOCK_TIMESTAMP}', F.lag(C.BLOCK_TIMESTAMP).over(w_ord)) \\\n",
    "        .withColumn('is_first_in_period', F.when(is_more_hours_lag_cond, 1).otherwise(0))\\\n",
    "        .withColumn('is_first_in_period', F.max('is_first_in_period').over(w_id)) \\\n",
    "        .dropDuplicates([C.BLOCK_TIMESTAMP, 'is_first_in_period'])\\\n",
    "        .filter(F.col('is_first_in_period') == 1)\\\n",
    "        .select(*final_cols_list)\\\n",
    "        .toPandas()\n",
    "\n",
    "    dic = {int(period_df['period'][i]): [period_df['f_min_period'][i], period_df['f_max_period'][i]]\n",
    "           for i in period_df.index.values.tolist()}\n",
    "\n",
    "    return dic\n",
    "\n",
    "def build_period_fun_from_dic(dic, colname):\n",
    "    stacked_cond = None\n",
    "    for k, v in dic.items():\n",
    "        cond = (F.col(colname) >= v[0]) & (F.col(colname) <= v[1])\n",
    "        stacked_cond = stacked_cond.when(cond, k) if stacked_cond is not None else F.when(cond, k)\n",
    "        \n",
    "    return stacked_cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = \\\n",
    "    spark.read.format('bigquery') \\\n",
    "    .option('table', TRANSACTIONS_FLATTEN_FULL_TABLENAME) \\\n",
    "    .option(\"filter\", f\"block_timestamp_month >= '{F_MIN}' AND block_timestamp_month < '{F_MAX}'\")\\\n",
    "    .load()\\\n",
    "    .select(C.INPUT_ADDRESS_ID,\n",
    "            C.OUTPUT_ADDRESS_ID,\n",
    "            C.BLOCK_TIMESTAMP,\n",
    "            'is_deanonymized',\n",
    "            'class')\n",
    "\n",
    "#Â transactions_df.count() -> 85738587\n",
    "# transactions_df.rdd.getNumPartitions() -> 843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217273420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|             3287946|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FILTER PERIODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = \\\n",
    "    transactions_df\\\n",
    "    .filter(F.col('is_deanonymized') == 1)\\\n",
    "    .groupBy('block_timestamp')\\\n",
    "    .count()\\\n",
    "    .orderBy('block_timestamp')\\\n",
    "    .toPandas()\n",
    "\n",
    "px.line(ts, x='block_timestamp', y='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ord = Window.orderBy('block_timestamp')\n",
    "w_id = Window.partitionBy('block_timestamp')\n",
    "\n",
    "diff_hours_lag_fun = (F.col('block_timestamp').cast('long') -  F.col('lag_block_timestamp').cast('long')) / 3600\n",
    "is_more_hours_lag_cond = (diff_hours_lag_fun > 3) | (F.col('lag_block_timestamp').isNull())\n",
    "\n",
    "first_transactions_df = \\\n",
    "    transactions_df\\\n",
    "    .filter(F.col('is_deanonymized') == 1)\\\n",
    "    .select('block_timestamp')\\\n",
    "    .withColumn('lag_block_timestamp', F.lag('block_timestamp').over(w_ord))\\\n",
    "    .withColumn('is_first_in_period',  F.when(is_more_hours_lag_cond, 1).otherwise(0))\\\n",
    "    .withColumn('is_first_in_period',  F.max('is_first_in_period').over(w_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_transactions_df\\\n",
    "    .filter(F.col('is_first_in_period') == 1)\\\n",
    "    .drop_duplicates(['block_timestamp', 'is_first_in_period'])\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_transactions_df \\\n",
    "    .filter(F.col('is_first_in_period') == 1)\\\n",
    "    .drop_duplicates(['block_timestamp', 'is_first_in_period'])\\\n",
    "    .groupBy(F.to_date('block_timestamp'))\\\n",
    "    .count()\\\n",
    "    .orderBy(F.desc('count'))\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_transactions_df\\\n",
    "    .filter(F.col('is_first_in_period') == 1)\\\n",
    "    .drop_duplicates(['block_timestamp', 'is_first_in_period'])\\\n",
    "    .withColumn('lag_block_timestamp', F.lag('block_timestamp').over(w_ord))\\\n",
    "    .withColumn('diff_lag', diff_hours_lag_fun)\\\n",
    "    .orderBy('block_timestamp')\\\n",
    "    .show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create period var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_dic = build_period_block_timestamp_dic(transactions_df, 3, 6)\n",
    "period_fun = build_period_fun_from_dic(period_dic, C.BLOCK_TIMESTAMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217273420"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_transactions_df = \\\n",
    "    transactions_df\\\n",
    "    .withColumn('period', period_fun)\\\n",
    "    .persist()\n",
    "\n",
    "period_transactions_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# period_transactions_df.groupBy('period').count().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = \\\n",
    "    period_transactions_df.filter(F.col('period').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['2016-01-01 02:50:56', '2016-01-01 08:50:56'],\n",
       " 2: ['2016-01-13 23:40:57', '2016-01-14 05:40:57'],\n",
       " 3: ['2016-01-27 04:01:32', '2016-01-27 10:01:32'],\n",
       " 4: ['2016-02-07 17:04:34', '2016-02-07 23:04:34'],\n",
       " 5: ['2016-02-20 05:43:02', '2016-02-20 11:43:02'],\n",
       " 6: ['2016-03-05 14:13:59', '2016-03-05 20:13:59'],\n",
       " 7: ['2016-03-19 03:05:12', '2016-03-19 09:05:12'],\n",
       " 8: ['2016-04-01 21:14:12', '2016-04-02 03:14:12'],\n",
       " 9: ['2016-04-14 22:53:05', '2016-04-15 04:53:05'],\n",
       " 10: ['2016-04-29 01:55:24', '2016-04-29 07:55:24'],\n",
       " 11: ['2016-05-11 23:10:38', '2016-05-12 05:10:38'],\n",
       " 12: ['2016-05-25 15:34:08', '2016-05-25 21:34:08'],\n",
       " 13: ['2016-06-08 18:08:38', '2016-06-09 00:08:38'],\n",
       " 14: ['2016-06-21 22:20:59', '2016-06-22 04:20:59'],\n",
       " 15: ['2016-07-05 17:19:48', '2016-07-05 23:19:48'],\n",
       " 16: ['2016-07-19 17:27:38', '2016-07-19 23:27:38'],\n",
       " 17: ['2016-08-03 10:01:52', '2016-08-03 16:01:52'],\n",
       " 18: ['2016-08-16 13:52:56', '2016-08-16 19:52:56'],\n",
       " 19: ['2016-08-30 06:26:15', '2016-08-30 12:26:15'],\n",
       " 20: ['2016-09-12 19:15:16', '2016-09-13 01:15:16'],\n",
       " 21: ['2016-09-25 21:50:08', '2016-09-26 03:50:08'],\n",
       " 22: ['2016-10-09 00:36:09', '2016-10-09 06:36:09'],\n",
       " 23: ['2016-10-23 10:58:25', '2016-10-23 16:58:25'],\n",
       " 24: ['2016-11-06 07:34:13', '2016-11-06 13:34:13'],\n",
       " 25: ['2016-11-18 23:59:04', '2016-11-19 05:59:04'],\n",
       " 26: ['2016-12-02 19:42:18', '2016-12-03 01:42:18'],\n",
       " 27: ['2016-12-15 20:26:20', '2016-12-16 02:26:20'],\n",
       " 28: ['2016-12-29 09:37:43', '2016-12-29 15:37:43'],\n",
       " 29: ['2017-01-11 12:49:44', '2017-01-11 18:49:44'],\n",
       " 30: ['2017-01-23 15:14:17', '2017-01-23 21:14:17'],\n",
       " 31: ['2017-02-05 13:26:08', '2017-02-05 19:26:08'],\n",
       " 32: ['2017-02-19 01:06:55', '2017-02-19 07:06:55'],\n",
       " 33: ['2017-03-04 11:05:28', '2017-03-04 17:05:28'],\n",
       " 34: ['2017-03-18 00:21:41', '2017-03-18 06:21:41'],\n",
       " 35: ['2017-03-31 07:38:56', '2017-03-31 13:38:56'],\n",
       " 36: ['2017-04-13 20:45:41', '2017-04-14 02:45:41'],\n",
       " 37: ['2017-04-27 20:05:46', '2017-04-28 02:05:46'],\n",
       " 38: ['2017-05-10 20:00:50', '2017-05-11 02:00:50'],\n",
       " 39: ['2017-05-23 22:00:57', '2017-05-24 04:00:57'],\n",
       " 40: ['2017-06-05 05:37:21', '2017-06-05 11:37:21'],\n",
       " 41: ['2017-06-18 16:13:50', '2017-06-18 22:13:50'],\n",
       " 42: ['2017-07-02 13:09:19', '2017-07-02 19:09:19'],\n",
       " 43: ['2017-07-15 03:48:27', '2017-07-15 09:48:27'],\n",
       " 44: ['2017-07-28 01:01:49', '2017-07-28 07:01:49'],\n",
       " 45: ['2017-08-10 05:38:54', '2017-08-10 11:38:54'],\n",
       " 46: ['2017-08-25 00:54:59', '2017-08-25 06:54:59'],\n",
       " 47: ['2017-09-07 03:20:23', '2017-09-07 09:20:23'],\n",
       " 48: ['2017-09-19 00:54:47', '2017-09-19 06:54:47']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GET CONNECTED NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_fun = build_period_fun_from_dic(PERIOD_DIC, C.BLOCK_TIMESTAMP)\n",
    "\n",
    "filtered_df = \\\n",
    "    transactions_df\\\n",
    "    .withColumn('period', period_fun)\\\n",
    "    .filter(F.col('period').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_count: 196913505\n"
     ]
    }
   ],
   "source": [
    "vertex_df = \\\n",
    "    filtered_df\\\n",
    "    .select(F.col(C.INPUT_ADDRESS_ID).alias('id'), 'is_deanonymized')\\\n",
    "    .unionByName(transactions_df\\\n",
    "                 .select(F.col(C.OUTPUT_ADDRESS_ID).alias('id'), 'is_deanonymized'))\\\n",
    "    .dropDuplicates(['id'])\\\n",
    "    .repartition(256)\\\n",
    "    .persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "print(f'vertex_count: {vertex_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges_count: 23427554\n"
     ]
    }
   ],
   "source": [
    "edges_df = \\\n",
    "    filtered_df\\\n",
    "    .select(F.col(C.INPUT_ADDRESS_ID).alias(C.SRC), F.col(C.OUTPUT_ADDRESS_ID).alias(C.DST), 'is_deanonymized')\\\n",
    "    .repartition(256)\\\n",
    "    .persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "print(f'edges_count: {edges_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gf.GraphFrame(vertex_df, edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=g.connectedComponents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196913505"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.persist()\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT component)|\n",
      "+-------------------------+\n",
      "|                189977291|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.countDistinct('component')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------------+\n",
      "|decomp|    count|count(component)|\n",
      "+------+---------+----------------+\n",
      "|     0|190955295|       189977290|\n",
      "|     1|  5958210|               1|\n",
      "+------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = Window.partitionBy('component')\n",
    "result\\\n",
    "    .withColumn('decomp', F.max('is_deanonymized').over(w))\\\n",
    "    .groupBy('decomp')\\\n",
    "    .agg(F.count(F.lit(1)).alias('count'),\n",
    "         F.countDistinct('component'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------+------------------+\n",
      "|                  id|is_deanonymized|component|is_valid_component|\n",
      "+--------------------+---------------+---------+------------------+\n",
      "|115iVZFSPFEW2Lt9M...|              0|        6|                 1|\n",
      "|12AikdxgTuBeAgZaG...|              0|        6|                 1|\n",
      "|12Fa8H4XJiGYzJZVQ...|              0|        6|                 1|\n",
      "|12TNcbwrCtL8F3Rog...|              0|        6|                 1|\n",
      "|12Uu5M2uUzYhbw8W8...|              0|        6|                 1|\n",
      "|12pS546ammzoApDEb...|              0|        6|                 1|\n",
      "|13KdyfMwriWoua4Qm...|              1|        6|                 1|\n",
      "|13LkLVxU6xnZoUMWB...|              1|        6|                 1|\n",
      "|13Y6BYhGJFeDruP3m...|              0|        6|                 1|\n",
      "|13YBn5Bu8jmw8bDh6...|              0|        6|                 1|\n",
      "|13sUpDwHoTjUYXuGZ...|              0|        6|                 1|\n",
      "|13trL8dPUVXFSE8qf...|              0|        6|                 1|\n",
      "|14NdrexB3q5j9Npph...|              1|        6|                 1|\n",
      "|155xrKQQg4tNiZFys...|              0|        6|                 1|\n",
      "|15JRnR6bdSHNUDURv...|              0|        6|                 1|\n",
      "|15RFRLcSwHzc4J4zV...|              0|        6|                 1|\n",
      "|15Yv4eZwdkLLWZEE8...|              0|        6|                 1|\n",
      "|15a7XDurzetKAh3H1...|              0|        6|                 1|\n",
      "|15orU9fKTCfbh5pxL...|              1|        6|                 1|\n",
      "|15pgWfniCsJz5WffL...|              0|        6|                 1|\n",
      "+--------------------+---------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result\\\n",
    "    .withColumn('is_valid_component', F.max('is_deanonymized').over(w))\\\n",
    "    .filter(F.col('is_valid_component') == 1)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|              367248|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result\\\n",
    "    .withColumn('is_valid_component', F.max('is_deanonymized').over(w))\\\n",
    "    .filter(F.col('is_valid_component') == 1)\\\n",
    "    .select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|             3287946|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|             3287946|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|              367248|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertex_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(is_deanonymized)|\n",
      "+--------------------+\n",
      "|             3287946|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges_df.select(F.sum('is_deanonymized')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_ks_crypto",
   "language": "python",
   "name": "p_ks_crypto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
